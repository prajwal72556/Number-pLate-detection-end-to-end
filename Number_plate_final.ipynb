{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adapted-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the Number plate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "technical-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "banned-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cropped_image(img):\n",
    "    car=cv2.CascadeClassifier(\"indian_license_plate.xml\")\n",
    "    photo=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    plate=car.detectMultiScale(photo)\n",
    "    for (x,y,w,h) in plate:\n",
    "        image=photo[y:y+h,x:x+w]\n",
    "        cv2.rectangle(photo,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        \n",
    "    return image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "celtic-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_image(image):\n",
    "    img=cv2.resize(image,(300,75))\n",
    "    _,binary_img=cv2.threshold(img,160,255,cv2.THRESH_BINARY)\n",
    "    erode_img=cv2.erode(binary_img,(3,3))\n",
    "    img_dilate = cv2.dilate(erode_img, (2,2))\n",
    "    \n",
    "    return img_dilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hollow-insert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "significant-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(img) :\n",
    "    cntrs, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:11]\n",
    "    x_cntr_list = []\n",
    "    target_contours = []\n",
    "    img_res = []\n",
    "    for cntr in cntrs :\n",
    "        x, y, w, h = cv2.boundingRect(cntr)\n",
    "        if ((w>=15) & (w<=340))  and h >= (processed_image.shape[0]>>1)-15:\n",
    "            x_cntr_list.append(x) \n",
    "            char = img[y:y+h, x:x+w]\n",
    "            char = cv2.resize(char, (20, 40))\n",
    "            char = cv2.subtract(255, char)\n",
    "            img_res.append(char) \n",
    "#Return characters on ascending order with respect to the x-coordinate (most-left character first)\n",
    "#arbitrary function that stores sorted list of character indeces\n",
    "    import numpy as np\n",
    "    indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])\n",
    "    img_res_copy = []\n",
    "    for idx in indices:\n",
    "        img_res_copy.append(img_res[idx])# stores character images according to their index\n",
    "    img_res = np.array(img_res_copy)\n",
    "\n",
    "    return img_res,x_cntr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "twelve-chrome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nphoto=cv2.imread(\"NP1.jpg\")\\ncropped_img=cropped_image(photo)\\nprocessed_image=processed_image(cropped_img)\\nprocessed_image.shape\\n\\n\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "photo=cv2.imread(\"NP1.jpg\")\n",
    "cropped_img=cropped_image(photo)\n",
    "processed_image=processed_image(cropped_img)\n",
    "processed_image.shape\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "provincial-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "internal-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "offensive-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(filters=64,kernel_size=(3,3),input_shape=(28,28,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "committed-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128,activation=\"relu\"))\n",
    "model.add(Dense(units=64,activation=\"relu\"))\n",
    "model.add(Dense(units=36,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "developing-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(),loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "identical-earthquake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 864 images belonging to 36 classes.\n",
      "Found 216 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "train_generator=train_datagen.flow_from_directory(\"/machineLearning/SummerTraining/computer_vision/Car/data/train\",target_size=(28,28),batch_size=1,class_mode=\"categorical\")\n",
    "\n",
    "test_generator=train_datagen.flow_from_directory(\"/machineLearning/SummerTraining/computer_vision/Car/data/val\",target_size=(28,28),batch_size=1,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "governmental-marriage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "216/216 [==============================] - 8s 20ms/step - loss: 3.4850 - accuracy: 0.0926 - val_loss: 3.1312 - val_accuracy: 0.1111\n",
      "Epoch 2/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 2.6338 - accuracy: 0.2778 - val_loss: 2.1580 - val_accuracy: 0.3657\n",
      "Epoch 3/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 1.7278 - accuracy: 0.4769 - val_loss: 1.4204 - val_accuracy: 0.5972\n",
      "Epoch 4/200\n",
      "216/216 [==============================] - 4s 19ms/step - loss: 1.2611 - accuracy: 0.5972 - val_loss: 1.2414 - val_accuracy: 0.5833\n",
      "Epoch 5/200\n",
      "216/216 [==============================] - 5s 22ms/step - loss: 0.9078 - accuracy: 0.6713 - val_loss: 0.9968 - val_accuracy: 0.6528\n",
      "Epoch 6/200\n",
      "216/216 [==============================] - 5s 24ms/step - loss: 0.6935 - accuracy: 0.7778 - val_loss: 1.0085 - val_accuracy: 0.6806\n",
      "Epoch 7/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.6964 - accuracy: 0.8148 - val_loss: 0.6070 - val_accuracy: 0.7870\n",
      "Epoch 8/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.6503 - accuracy: 0.7731 - val_loss: 0.6939 - val_accuracy: 0.7546\n",
      "Epoch 9/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.4799 - accuracy: 0.8472 - val_loss: 0.4880 - val_accuracy: 0.8380\n",
      "Epoch 10/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.5097 - accuracy: 0.8056 - val_loss: 0.4600 - val_accuracy: 0.8657\n",
      "Epoch 11/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.4587 - accuracy: 0.8333 - val_loss: 0.5074 - val_accuracy: 0.8380\n",
      "Epoch 12/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.3582 - accuracy: 0.8981 - val_loss: 0.6955 - val_accuracy: 0.7824\n",
      "Epoch 13/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.3868 - accuracy: 0.8889 - val_loss: 0.4886 - val_accuracy: 0.8241\n",
      "Epoch 14/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.3867 - accuracy: 0.8750 - val_loss: 0.4687 - val_accuracy: 0.8426\n",
      "Epoch 15/200\n",
      "216/216 [==============================] - 5s 21ms/step - loss: 0.3782 - accuracy: 0.8519 - val_loss: 0.3121 - val_accuracy: 0.9028\n",
      "Epoch 16/200\n",
      "216/216 [==============================] - 4s 19ms/step - loss: 0.2337 - accuracy: 0.9398 - val_loss: 0.3810 - val_accuracy: 0.8796\n",
      "Epoch 17/200\n",
      "216/216 [==============================] - 4s 20ms/step - loss: 0.2832 - accuracy: 0.8981 - val_loss: 0.4156 - val_accuracy: 0.8750\n",
      "Epoch 18/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.3485 - accuracy: 0.8796 - val_loss: 0.5529 - val_accuracy: 0.8380\n",
      "Epoch 19/200\n",
      "216/216 [==============================] - 4s 20ms/step - loss: 0.2301 - accuracy: 0.9213 - val_loss: 0.3005 - val_accuracy: 0.8935\n",
      "Epoch 20/200\n",
      "216/216 [==============================] - 6s 26ms/step - loss: 0.1260 - accuracy: 0.9491 - val_loss: 0.1934 - val_accuracy: 0.9167\n",
      "Epoch 21/200\n",
      "216/216 [==============================] - 5s 23ms/step - loss: 0.2387 - accuracy: 0.9352 - val_loss: 0.3898 - val_accuracy: 0.8565\n",
      "Epoch 22/200\n",
      "216/216 [==============================] - 5s 23ms/step - loss: 0.2378 - accuracy: 0.9306 - val_loss: 0.4565 - val_accuracy: 0.8472\n",
      "Epoch 23/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.2477 - accuracy: 0.9167 - val_loss: 0.3613 - val_accuracy: 0.8843\n",
      "Epoch 24/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1747 - accuracy: 0.9444 - val_loss: 0.3445 - val_accuracy: 0.9028\n",
      "Epoch 25/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.1754 - accuracy: 0.9259 - val_loss: 0.3146 - val_accuracy: 0.9213\n",
      "Epoch 26/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.2388 - accuracy: 0.9213 - val_loss: 0.3876 - val_accuracy: 0.9028\n",
      "Epoch 27/200\n",
      "216/216 [==============================] - 5s 21ms/step - loss: 0.1989 - accuracy: 0.9306 - val_loss: 0.3508 - val_accuracy: 0.8796\n",
      "Epoch 28/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.2424 - accuracy: 0.9074 - val_loss: 0.2312 - val_accuracy: 0.9213\n",
      "Epoch 29/200\n",
      "216/216 [==============================] - 5s 21ms/step - loss: 0.1229 - accuracy: 0.9583 - val_loss: 0.3738 - val_accuracy: 0.9167\n",
      "Epoch 30/200\n",
      "216/216 [==============================] - 5s 20ms/step - loss: 0.1668 - accuracy: 0.9306 - val_loss: 0.2453 - val_accuracy: 0.9074\n",
      "Epoch 31/200\n",
      "216/216 [==============================] - 5s 23ms/step - loss: 0.2683 - accuracy: 0.8935 - val_loss: 0.2873 - val_accuracy: 0.8935\n",
      "Epoch 32/200\n",
      "216/216 [==============================] - 5s 22ms/step - loss: 0.1368 - accuracy: 0.9306 - val_loss: 0.2423 - val_accuracy: 0.9167\n",
      "Epoch 33/200\n",
      "216/216 [==============================] - 5s 21ms/step - loss: 0.3302 - accuracy: 0.8796 - val_loss: 0.1420 - val_accuracy: 0.9583\n",
      "Epoch 34/200\n",
      "216/216 [==============================] - 4s 19ms/step - loss: 0.1313 - accuracy: 0.9398 - val_loss: 0.1347 - val_accuracy: 0.9398\n",
      "Epoch 35/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.1133 - accuracy: 0.9630 - val_loss: 0.1604 - val_accuracy: 0.9398\n",
      "Epoch 36/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.1369 - accuracy: 0.9583 - val_loss: 0.2829 - val_accuracy: 0.9213\n",
      "Epoch 37/200\n",
      "216/216 [==============================] - 5s 21ms/step - loss: 0.2161 - accuracy: 0.9398 - val_loss: 0.2807 - val_accuracy: 0.9028\n",
      "Epoch 38/200\n",
      "216/216 [==============================] - 5s 21ms/step - loss: 0.1460 - accuracy: 0.9630 - val_loss: 0.1618 - val_accuracy: 0.9444\n",
      "Epoch 39/200\n",
      "216/216 [==============================] - 4s 20ms/step - loss: 0.2420 - accuracy: 0.9213 - val_loss: 0.1390 - val_accuracy: 0.9444\n",
      "Epoch 40/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.1277 - accuracy: 0.9583 - val_loss: 0.1432 - val_accuracy: 0.9398\n",
      "Epoch 41/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.1561 - accuracy: 0.9398 - val_loss: 0.1898 - val_accuracy: 0.9352\n",
      "Epoch 42/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.2207 - accuracy: 0.9259 - val_loss: 0.1906 - val_accuracy: 0.9259\n",
      "Epoch 43/200\n",
      "216/216 [==============================] - 4s 19ms/step - loss: 0.0544 - accuracy: 0.9815 - val_loss: 0.1262 - val_accuracy: 0.9537\n",
      "Epoch 44/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.1107 - accuracy: 0.9537 - val_loss: 0.1283 - val_accuracy: 0.9537\n",
      "Epoch 45/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.1677 - accuracy: 0.9583 - val_loss: 0.1747 - val_accuracy: 0.9352\n",
      "Epoch 46/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.0645 - accuracy: 0.9769 - val_loss: 0.1282 - val_accuracy: 0.9398\n",
      "Epoch 47/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.1589 - accuracy: 0.9444 - val_loss: 0.1058 - val_accuracy: 0.9630\n",
      "Epoch 48/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.1347 - accuracy: 0.9491 - val_loss: 0.2768 - val_accuracy: 0.8889\n",
      "Epoch 49/200\n",
      "216/216 [==============================] - 4s 19ms/step - loss: 0.1813 - accuracy: 0.9306 - val_loss: 0.0900 - val_accuracy: 0.9722\n",
      "Epoch 50/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.1418 - accuracy: 0.9352 - val_loss: 0.1021 - val_accuracy: 0.9583\n",
      "Epoch 51/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.0803 - accuracy: 0.9769 - val_loss: 0.0980 - val_accuracy: 0.9537\n",
      "Epoch 52/200\n",
      "216/216 [==============================] - 5s 23ms/step - loss: 0.2598 - accuracy: 0.9537 - val_loss: 0.1334 - val_accuracy: 0.9630\n",
      "Epoch 53/200\n",
      "216/216 [==============================] - 4s 18ms/step - loss: 0.0974 - accuracy: 0.9491 - val_loss: 0.0926 - val_accuracy: 0.9537\n",
      "Epoch 54/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.1427 - accuracy: 0.9444 - val_loss: 0.2406 - val_accuracy: 0.9167\n",
      "Epoch 55/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.0900 - accuracy: 0.9676 - val_loss: 0.1066 - val_accuracy: 0.9583\n",
      "Epoch 56/200\n",
      "216/216 [==============================] - 4s 19ms/step - loss: 0.0992 - accuracy: 0.9769 - val_loss: 0.1143 - val_accuracy: 0.9630\n",
      "Epoch 57/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.1344 - accuracy: 0.9583 - val_loss: 0.1949 - val_accuracy: 0.9352\n",
      "Epoch 58/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0642 - accuracy: 0.9769 - val_loss: 0.1290 - val_accuracy: 0.9537\n",
      "Epoch 59/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.1156 - accuracy: 0.9537 - val_loss: 0.1147 - val_accuracy: 0.9630\n",
      "Epoch 60/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1252 - accuracy: 0.9722 - val_loss: 0.0731 - val_accuracy: 0.9676\n",
      "Epoch 61/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0707 - accuracy: 0.9815 - val_loss: 0.1555 - val_accuracy: 0.9491\n",
      "Epoch 62/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1295 - accuracy: 0.9583 - val_loss: 0.0919 - val_accuracy: 0.9722\n",
      "Epoch 63/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0422 - accuracy: 0.9815 - val_loss: 0.1301 - val_accuracy: 0.9583\n",
      "Epoch 64/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0673 - accuracy: 0.9676 - val_loss: 0.2467 - val_accuracy: 0.9259\n",
      "Epoch 65/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1191 - accuracy: 0.9491 - val_loss: 0.1390 - val_accuracy: 0.9583\n",
      "Epoch 66/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.2059 - accuracy: 0.9352 - val_loss: 0.1298 - val_accuracy: 0.9398\n",
      "Epoch 67/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0568 - accuracy: 0.9722 - val_loss: 0.0896 - val_accuracy: 0.9630\n",
      "Epoch 68/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1470 - accuracy: 0.9630 - val_loss: 0.1554 - val_accuracy: 0.9444\n",
      "Epoch 69/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1347 - accuracy: 0.9537 - val_loss: 0.2907 - val_accuracy: 0.9306\n",
      "Epoch 70/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1366 - accuracy: 0.9491 - val_loss: 0.1961 - val_accuracy: 0.9444\n",
      "Epoch 71/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.1080 - accuracy: 0.9676 - val_loss: 0.0543 - val_accuracy: 0.9815\n",
      "Epoch 72/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0977 - accuracy: 0.9630 - val_loss: 0.1599 - val_accuracy: 0.9306\n",
      "Epoch 73/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0723 - accuracy: 0.9722 - val_loss: 0.2305 - val_accuracy: 0.9352\n",
      "Epoch 74/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0344 - accuracy: 0.9861 - val_loss: 0.0592 - val_accuracy: 0.9815\n",
      "Epoch 75/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0403 - accuracy: 0.9861 - val_loss: 0.1348 - val_accuracy: 0.9583\n",
      "Epoch 76/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.1566 - accuracy: 0.9583 - val_loss: 0.2163 - val_accuracy: 0.9213\n",
      "Epoch 77/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1148 - accuracy: 0.9583 - val_loss: 0.3023 - val_accuracy: 0.9259\n",
      "Epoch 78/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0783 - accuracy: 0.9676 - val_loss: 0.1760 - val_accuracy: 0.9491\n",
      "Epoch 79/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0735 - accuracy: 0.9676 - val_loss: 0.1059 - val_accuracy: 0.9583\n",
      "Epoch 80/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.1529 - accuracy: 0.9537 - val_loss: 0.0842 - val_accuracy: 0.9583\n",
      "Epoch 81/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0904 - accuracy: 0.9676 - val_loss: 0.1175 - val_accuracy: 0.9676\n",
      "Epoch 82/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0397 - accuracy: 0.9861 - val_loss: 0.0710 - val_accuracy: 0.9769\n",
      "Epoch 83/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.0524 - accuracy: 0.9815 - val_loss: 0.0546 - val_accuracy: 0.9769\n",
      "Epoch 84/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0516 - accuracy: 0.9769 - val_loss: 0.1130 - val_accuracy: 0.9491\n",
      "Epoch 85/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.1003 - accuracy: 0.9676 - val_loss: 0.0903 - val_accuracy: 0.9722\n",
      "Epoch 86/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0762 - accuracy: 0.9769 - val_loss: 0.0719 - val_accuracy: 0.9722\n",
      "Epoch 87/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1365 - accuracy: 0.9583 - val_loss: 0.3388 - val_accuracy: 0.8935\n",
      "Epoch 88/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.2088 - accuracy: 0.9213 - val_loss: 0.1004 - val_accuracy: 0.9722\n",
      "Epoch 89/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0788 - accuracy: 0.9676 - val_loss: 0.1547 - val_accuracy: 0.9398\n",
      "Epoch 90/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0700 - accuracy: 0.9676 - val_loss: 0.1409 - val_accuracy: 0.9583\n",
      "Epoch 91/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0889 - accuracy: 0.9583 - val_loss: 0.1072 - val_accuracy: 0.9583\n",
      "Epoch 92/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0505 - accuracy: 0.9815 - val_loss: 0.0710 - val_accuracy: 0.9861\n",
      "Epoch 93/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1068 - accuracy: 0.9491 - val_loss: 0.1362 - val_accuracy: 0.9630\n",
      "Epoch 94/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1136 - accuracy: 0.9491 - val_loss: 0.1887 - val_accuracy: 0.9676\n",
      "Epoch 95/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1615 - accuracy: 0.9398 - val_loss: 0.1324 - val_accuracy: 0.9630\n",
      "Epoch 96/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0453 - accuracy: 0.9861 - val_loss: 0.1222 - val_accuracy: 0.9676\n",
      "Epoch 97/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0950 - accuracy: 0.9769 - val_loss: 0.3017 - val_accuracy: 0.9306\n",
      "Epoch 98/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1243 - accuracy: 0.9630 - val_loss: 0.1884 - val_accuracy: 0.9630\n",
      "Epoch 99/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0334 - accuracy: 0.9815 - val_loss: 0.2042 - val_accuracy: 0.9491\n",
      "Epoch 100/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0631 - accuracy: 0.9769 - val_loss: 0.0801 - val_accuracy: 0.9722\n",
      "Epoch 101/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0344 - accuracy: 0.9815 - val_loss: 0.0738 - val_accuracy: 0.9676\n",
      "Epoch 102/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0621 - accuracy: 0.9676 - val_loss: 0.1707 - val_accuracy: 0.9583\n",
      "Epoch 103/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0427 - accuracy: 0.9769 - val_loss: 0.0622 - val_accuracy: 0.9861\n",
      "Epoch 104/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0765 - accuracy: 0.9769 - val_loss: 0.0695 - val_accuracy: 0.9861\n",
      "Epoch 105/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.1730 - accuracy: 0.9491 - val_loss: 0.2816 - val_accuracy: 0.9491\n",
      "Epoch 106/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0931 - accuracy: 0.9722 - val_loss: 0.0397 - val_accuracy: 0.9861\n",
      "Epoch 107/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0825 - accuracy: 0.9444 - val_loss: 0.0972 - val_accuracy: 0.9583\n",
      "Epoch 108/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0620 - accuracy: 0.9722 - val_loss: 0.1265 - val_accuracy: 0.9583\n",
      "Epoch 109/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0971 - accuracy: 0.9537 - val_loss: 0.2660 - val_accuracy: 0.9120\n",
      "Epoch 110/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0512 - accuracy: 0.9769 - val_loss: 0.0489 - val_accuracy: 0.9769\n",
      "Epoch 111/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0366 - accuracy: 0.9907 - val_loss: 0.0470 - val_accuracy: 0.9815\n",
      "Epoch 112/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0814 - accuracy: 0.9722 - val_loss: 0.1135 - val_accuracy: 0.9583\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0702 - accuracy: 0.9722 - val_loss: 0.1182 - val_accuracy: 0.9630\n",
      "Epoch 114/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0354 - accuracy: 0.9907 - val_loss: 0.0837 - val_accuracy: 0.9769\n",
      "Epoch 115/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.1418 - val_accuracy: 0.9630\n",
      "Epoch 116/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1078 - accuracy: 0.9722 - val_loss: 0.1215 - val_accuracy: 0.9630\n",
      "Epoch 117/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0709 - accuracy: 0.9722 - val_loss: 0.0933 - val_accuracy: 0.9583\n",
      "Epoch 118/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0704 - accuracy: 0.9630 - val_loss: 0.0204 - val_accuracy: 0.9954\n",
      "Epoch 119/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1293 - accuracy: 0.9491 - val_loss: 0.1876 - val_accuracy: 0.9630\n",
      "Epoch 120/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0682 - accuracy: 0.9722 - val_loss: 0.0637 - val_accuracy: 0.9861\n",
      "Epoch 121/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0390 - accuracy: 0.9861 - val_loss: 0.0443 - val_accuracy: 0.9907\n",
      "Epoch 122/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0829 - accuracy: 0.9630 - val_loss: 0.0702 - val_accuracy: 0.9676\n",
      "Epoch 123/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.0729 - accuracy: 0.9676 - val_loss: 0.1505 - val_accuracy: 0.9676\n",
      "Epoch 124/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0683 - accuracy: 0.9815 - val_loss: 0.1240 - val_accuracy: 0.9537\n",
      "Epoch 125/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1107 - accuracy: 0.9676 - val_loss: 0.0485 - val_accuracy: 0.9769\n",
      "Epoch 126/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0357 - accuracy: 0.9907 - val_loss: 0.1219 - val_accuracy: 0.9676\n",
      "Epoch 127/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.0429 - accuracy: 0.9907 - val_loss: 0.1562 - val_accuracy: 0.9444\n",
      "Epoch 128/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.0447 - accuracy: 0.9769 - val_loss: 0.0519 - val_accuracy: 0.9676\n",
      "Epoch 129/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0449 - accuracy: 0.9815 - val_loss: 0.0442 - val_accuracy: 0.9722\n",
      "Epoch 130/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0558 - accuracy: 0.9722 - val_loss: 0.0776 - val_accuracy: 0.9769\n",
      "Epoch 131/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0300 - accuracy: 0.9907 - val_loss: 0.1332 - val_accuracy: 0.9491\n",
      "Epoch 132/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0821 - accuracy: 0.9769 - val_loss: 0.0653 - val_accuracy: 0.9630\n",
      "Epoch 133/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1589 - accuracy: 0.9491 - val_loss: 0.1058 - val_accuracy: 0.9537\n",
      "Epoch 134/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0432 - accuracy: 0.9769 - val_loss: 0.1723 - val_accuracy: 0.9398\n",
      "Epoch 135/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0973 - accuracy: 0.9769 - val_loss: 0.1263 - val_accuracy: 0.9444\n",
      "Epoch 136/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.1095 - val_accuracy: 0.9630\n",
      "Epoch 137/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0915 - accuracy: 0.9537 - val_loss: 0.0491 - val_accuracy: 0.9861\n",
      "Epoch 138/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0539 - accuracy: 0.9722 - val_loss: 0.0474 - val_accuracy: 0.9722\n",
      "Epoch 139/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1455 - accuracy: 0.9722 - val_loss: 0.0993 - val_accuracy: 0.9676\n",
      "Epoch 140/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0886 - accuracy: 0.9630 - val_loss: 0.1247 - val_accuracy: 0.9630\n",
      "Epoch 141/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0383 - accuracy: 0.9861 - val_loss: 0.0715 - val_accuracy: 0.9722\n",
      "Epoch 142/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0888 - accuracy: 0.9722 - val_loss: 0.2037 - val_accuracy: 0.9769\n",
      "Epoch 143/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.1323 - accuracy: 0.9722 - val_loss: 0.0755 - val_accuracy: 0.9676\n",
      "Epoch 144/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0594 - accuracy: 0.9722 - val_loss: 0.0989 - val_accuracy: 0.9769\n",
      "Epoch 145/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0532 - accuracy: 0.9722 - val_loss: 0.0365 - val_accuracy: 0.9861\n",
      "Epoch 146/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0405 - accuracy: 0.9861 - val_loss: 0.0953 - val_accuracy: 0.9722\n",
      "Epoch 147/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0175 - accuracy: 0.9954 - val_loss: 0.0441 - val_accuracy: 0.9907\n",
      "Epoch 148/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0535 - accuracy: 0.9861 - val_loss: 0.1497 - val_accuracy: 0.9769\n",
      "Epoch 149/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0488 - accuracy: 0.9815 - val_loss: 0.0824 - val_accuracy: 0.9676\n",
      "Epoch 150/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.1268 - accuracy: 0.9491 - val_loss: 0.0367 - val_accuracy: 0.9815\n",
      "Epoch 151/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0545 - accuracy: 0.9769 - val_loss: 0.1446 - val_accuracy: 0.9583\n",
      "Epoch 152/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0231 - accuracy: 0.9907 - val_loss: 0.0620 - val_accuracy: 0.9583\n",
      "Epoch 153/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0800 - accuracy: 0.9769 - val_loss: 0.0576 - val_accuracy: 0.9769\n",
      "Epoch 154/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0341 - accuracy: 0.9907 - val_loss: 0.0634 - val_accuracy: 0.9630\n",
      "Epoch 155/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0777 - accuracy: 0.9769 - val_loss: 0.1645 - val_accuracy: 0.9537\n",
      "Epoch 156/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0691 - accuracy: 0.9722 - val_loss: 0.0758 - val_accuracy: 0.9676\n",
      "Epoch 157/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0710 - accuracy: 0.9630 - val_loss: 0.0571 - val_accuracy: 0.9815\n",
      "Epoch 158/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0223 - accuracy: 0.9861 - val_loss: 0.0716 - val_accuracy: 0.9630\n",
      "Epoch 159/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0428 - accuracy: 0.9815 - val_loss: 0.1172 - val_accuracy: 0.9676\n",
      "Epoch 160/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0505 - accuracy: 0.9861 - val_loss: 0.1660 - val_accuracy: 0.9444\n",
      "Epoch 161/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0875 - accuracy: 0.9537 - val_loss: 0.0461 - val_accuracy: 0.9861\n",
      "Epoch 162/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0777 - accuracy: 0.9676 - val_loss: 0.0656 - val_accuracy: 0.9722\n",
      "Epoch 163/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0758 - accuracy: 0.9676 - val_loss: 0.0987 - val_accuracy: 0.9630\n",
      "Epoch 164/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0361 - accuracy: 0.9815 - val_loss: 0.1295 - val_accuracy: 0.9630\n",
      "Epoch 165/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0750 - accuracy: 0.9769 - val_loss: 0.0502 - val_accuracy: 0.9815\n",
      "Epoch 166/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0383 - accuracy: 0.9815 - val_loss: 0.0447 - val_accuracy: 0.9815\n",
      "Epoch 167/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0551 - accuracy: 0.9815 - val_loss: 0.0586 - val_accuracy: 0.9861\n",
      "Epoch 168/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0512 - accuracy: 0.9676 - val_loss: 0.1026 - val_accuracy: 0.9583\n",
      "Epoch 169/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.1139 - accuracy: 0.9676 - val_loss: 0.2083 - val_accuracy: 0.9769\n",
      "Epoch 170/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1479 - accuracy: 0.9583 - val_loss: 0.0662 - val_accuracy: 0.9815\n",
      "Epoch 171/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0915 - accuracy: 0.9722 - val_loss: 0.1488 - val_accuracy: 0.9583\n",
      "Epoch 172/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.0449 - accuracy: 0.9861 - val_loss: 0.0564 - val_accuracy: 0.9907\n",
      "Epoch 173/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.0481 - accuracy: 0.9676 - val_loss: 0.0372 - val_accuracy: 0.9861\n",
      "Epoch 174/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0422 - accuracy: 0.9861 - val_loss: 0.0555 - val_accuracy: 0.9722\n",
      "Epoch 175/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.0916 - val_accuracy: 0.9630\n",
      "Epoch 176/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0765 - accuracy: 0.9815 - val_loss: 0.0807 - val_accuracy: 0.9769\n",
      "Epoch 177/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0760 - accuracy: 0.9722 - val_loss: 0.2308 - val_accuracy: 0.9444\n",
      "Epoch 178/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1194 - accuracy: 0.9676 - val_loss: 0.0599 - val_accuracy: 0.9676\n",
      "Epoch 179/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0461 - accuracy: 0.9815 - val_loss: 0.1443 - val_accuracy: 0.9722\n",
      "Epoch 180/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0168 - accuracy: 0.9907 - val_loss: 0.0859 - val_accuracy: 0.9861\n",
      "Epoch 181/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0484 - accuracy: 0.9815 - val_loss: 0.0246 - val_accuracy: 0.9907\n",
      "Epoch 182/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0319 - accuracy: 0.9815 - val_loss: 0.0752 - val_accuracy: 0.9583\n",
      "Epoch 183/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0525 - accuracy: 0.9815 - val_loss: 0.0280 - val_accuracy: 0.9907\n",
      "Epoch 184/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0183 - accuracy: 0.9954 - val_loss: 0.1381 - val_accuracy: 0.9583\n",
      "Epoch 185/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1647 - accuracy: 0.9583 - val_loss: 0.0627 - val_accuracy: 0.9769\n",
      "Epoch 186/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0931 - accuracy: 0.9769 - val_loss: 0.0959 - val_accuracy: 0.9537\n",
      "Epoch 187/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0840 - accuracy: 0.9769 - val_loss: 0.0885 - val_accuracy: 0.9630\n",
      "Epoch 188/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 0.0883 - val_accuracy: 0.9722\n",
      "Epoch 189/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0697 - accuracy: 0.9722 - val_loss: 0.2284 - val_accuracy: 0.9630\n",
      "Epoch 190/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0531 - accuracy: 0.9769 - val_loss: 0.0601 - val_accuracy: 0.9861\n",
      "Epoch 191/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.1610 - accuracy: 0.9630 - val_loss: 0.0924 - val_accuracy: 0.9676\n",
      "Epoch 192/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0269 - accuracy: 0.9861 - val_loss: 0.1013 - val_accuracy: 0.9769\n",
      "Epoch 193/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0525 - accuracy: 0.9815 - val_loss: 0.1009 - val_accuracy: 0.9583\n",
      "Epoch 194/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.1267 - accuracy: 0.9722 - val_loss: 0.1476 - val_accuracy: 0.9444\n",
      "Epoch 195/200\n",
      "216/216 [==============================] - 3s 16ms/step - loss: 0.0939 - accuracy: 0.9861 - val_loss: 0.0988 - val_accuracy: 0.9583\n",
      "Epoch 196/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0533 - accuracy: 0.9815 - val_loss: 0.1008 - val_accuracy: 0.9861\n",
      "Epoch 197/200\n",
      "216/216 [==============================] - 4s 16ms/step - loss: 0.0324 - accuracy: 0.9907 - val_loss: 0.1663 - val_accuracy: 0.9769\n",
      "Epoch 198/200\n",
      "216/216 [==============================] - 3s 15ms/step - loss: 0.0482 - accuracy: 0.9769 - val_loss: 0.1130 - val_accuracy: 0.9769\n",
      "Epoch 199/200\n",
      "216/216 [==============================] - 5s 20ms/step - loss: 0.0359 - accuracy: 0.9815 - val_loss: 0.1030 - val_accuracy: 0.9630\n",
      "Epoch 200/200\n",
      "216/216 [==============================] - 4s 17ms/step - loss: 0.0524 - accuracy: 0.9815 - val_loss: 0.0294 - val_accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b1facc1a08>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=216,validation_data=test_generator,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "liable-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Number_Plate_Production_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-gentleman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "included-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 300)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo=cv2.imread(\"NP1.jpg\")\n",
    "cropped_img=cropped_image(photo)\n",
    "processed_image=processed_image(cropped_img)\n",
    "processed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "light-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "char,x_list=find_contours(processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "minimal-prague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 11 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(11):\n",
    "    plt.subplot(1, 11, i+1)\n",
    "    plt.imshow(char[i], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "suffering-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "every-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"Number_Plate_Production_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "precise-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dimension(img): \n",
    "    new_img = np.zeros((28,28,3))\n",
    "    for i in range(3):\n",
    "        new_img[:,:,i] = img\n",
    "    return new_img\n",
    "  \n",
    "def show_results():\n",
    "    dic = {}\n",
    "    characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    for i,c in enumerate(characters):\n",
    "        dic[i] = c\n",
    "\n",
    "    output = []\n",
    "    for i,ch in enumerate(char): #iterating over the characters\n",
    "        img_ = cv2.resize(ch, (28,28))\n",
    "        img = fix_dimension(img_)\n",
    "        img = img.reshape(1,28,28,3) #preparing image for the model\n",
    "        predict_x=model.predict(img) \n",
    "        y=np.argmax(predict_x,axis=1)[0]\n",
    "        character = dic[y] \n",
    "        output.append(character) #storing the result in a list\n",
    "        \n",
    "    plate_number = ''.join(output)\n",
    "    \n",
    "    return plate_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cleared-showcase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QCG0JME2250\n"
     ]
    }
   ],
   "source": [
    "print(show_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-relay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def find_contours_rectangle(processed_image):\n",
    "    import numpy as np\n",
    "    contours=cv2.findContours(processed_image,cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    cntrs = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    proc=processed_image.copy()\n",
    "    cnt=[]\n",
    "    img_chars=[]\n",
    "    \n",
    "    for c in cntrs:\n",
    "        (x,y,w,h)=cv2.boundingRect(c)\n",
    "        if (w>=15 & w<=340)  and h >= (processed_image.shape[0]>>1)-15:\n",
    "            \n",
    "            x1=x+w\n",
    "            y1=y+h\n",
    "            cnt.append([x,y,x1,y1])\n",
    "            cv2.rectangle(proc,(x,y),(x1,y1),(0,255,0),2)\n",
    "            char_copy = np.zeros((44,24))\n",
    "            \n",
    "            char = proc[y:y1, x:x1]\n",
    "            char = cv2.resize(char, (20, 40))\n",
    "\n",
    "            # Make result formatted for classification: invert colors\n",
    "            char = cv2.subtract(255, char)\n",
    "\n",
    "            # Resize the image to 24x44 with black border\n",
    "            #char_copy[2:42, 2:22] = char\n",
    "            img_chars.append(char)\n",
    "    \n",
    "\n",
    "    return img_chars, proc\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def find_contours_rectangle(processed_image):\n",
    "    contours=cv2.findContours(processed_image,cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    cntrs = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    proc=processed_image.copy()\n",
    "    cnt=[]\n",
    "    x_c=[]\n",
    "    nh,wh=processed_image.shape\n",
    "    images=[]\n",
    "    for c in cntrs:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "        #if h < 0.3 * nh:\n",
    "         #   continue\n",
    "            \n",
    "        if (w>=15 & w<=340)  and h >= (processed_image.shape[0]>>1)-15:\n",
    "            x_c.append(x)\n",
    "            x1=x+w\n",
    "            y1=y+h\n",
    "            cnt.append([x,y,x1,y1])\n",
    "            cv2.rectangle(proc, (x,y), (x1,y1), (0,255, 0), 1, cv2.LINE_AA)\n",
    "            images.append(processed_image[y:y1,x:x1])\n",
    "            \n",
    "    return x_c\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
